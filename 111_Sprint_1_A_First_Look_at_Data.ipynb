{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "111 Sprint 1 - A First Look at Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielleRomanoff/DS-Sprint-01-Dealing-With-Data/blob/master/111_Sprint_1_A_First_Look_at_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Okfr_uhwhS1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science - A First Look at Data\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9dtJETFRhnOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lecture - let's explore Python DS libraries and examples!\n",
        "\n",
        "The Python Data Science ecosystem is huge. You've seen some of the big pieces - pandas, scikit-learn, matplotlib. What parts do you want to see more of?"
      ]
    },
    {
      "metadata": {
        "id": "WiBkgmPJhmhE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO - we'll be doing this live, taking requests\n",
        "# and reproducing what it is to look up and learn things\n",
        "1+1\n",
        "\n",
        "# As the one most focused on machine learning, libraries like scikit-learn, keras, tensorflow etc. are all things I am most interested in right now"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOqaPds9huME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment - now it's your turn\n",
        "\n",
        "Pick at least one Python DS library, and using documentation/examples reproduce in this notebook something cool. It's OK if you don't fully understand it or get it 100% working, but do put in effort and look things up."
      ]
    },
    {
      "metadata": {
        "id": "TGUS79cOhPWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO - your code here\n",
        "# Use what we did live in lecture as an example\n",
        "\n",
        "!wget -nc --no-check-certificate https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip && unzip -n inception5h.zip\n",
        "!wget -nc https://www.shutterbug.com/images/styles/600_wide/public/promompi3718.png # New file download\n",
        "file_contents = open(\"promompi3718.png\", \"rb\").read() # New file read (now in bindary)\n",
        "\n",
        "from io import BytesIO\n",
        "from IPython.display import clear_output, Image, display\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "from __future__ import print_function\n",
        "\n",
        "model_fn = 'tensorflow_inception_graph.pb'\n",
        "\n",
        "# creating TensorFlow session and loading the model\n",
        "graph = tf.Graph()\n",
        "sess = tf.InteractiveSession(graph=graph)\n",
        "with tf.gfile.FastGFile(model_fn, 'rb') as f:\n",
        "    graph_def = tf.GraphDef()\n",
        "    graph_def.ParseFromString(f.read())\n",
        "t_input = tf.placeholder(np.float32, name='input') # define the input tensor\n",
        "imagenet_mean = 117.0\n",
        "t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)\n",
        "tf.import_graph_def(graph_def, {'input':t_preprocessed})\n",
        "\n",
        "def T(layer):\n",
        "    '''Helper for getting layer output tensor'''\n",
        "    return graph.get_tensor_by_name(\"import/%s:0\"%layer)\n",
        "  \n",
        "def showarray(a, fmt='jpeg'):\n",
        "    a = np.uint8(np.clip(a, 0, 255))\n",
        "    f = BytesIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    display(Image(data=f.getvalue()))\n",
        "img0 = sess.run(tf.image.decode_image(file_contents))\n",
        "img0 = np.float32(img0)[:,:,:3]\n",
        "\n",
        "# Helper function that uses TensorFlow to resize an image\n",
        "def resize(img, new_size):\n",
        "    return sess.run(tf.image.resize_bilinear(img[np.newaxis,:], new_size))[0]\n",
        "\n",
        "# Apply gradients to an image in a seires of tiles\n",
        "def calc_grad_tiled(img, t_grad, tile_size=256):\n",
        "    '''Random shifts are applied to the image to blur tile boundaries over\n",
        "    multiple iterations.'''\n",
        "    h, w = img.shape[:2]\n",
        "    sx, sy = np.random.randint(tile_size, size=2)\n",
        "    # We randomly roll the image in x and y to avoid seams between tiles.\n",
        "    img_shift = np.roll(np.roll(img, sx, 1), sy, 0)\n",
        "    grad = np.zeros_like(img)\n",
        "    for y in range(0, max(h-tile_size//2, tile_size),tile_size):\n",
        "        for x in range(0, max(w-tile_size//2, tile_size),tile_size):\n",
        "            sub = img_shift[y:y+tile_size,x:x+tile_size]\n",
        "            g = sess.run(t_grad, {t_input:sub})\n",
        "            grad[y:y+tile_size,x:x+tile_size] = g\n",
        "    imggrad = np.roll(np.roll(grad, -sx, 1), -sy, 0)\n",
        "    # Add the image gradient to the image and return the result\n",
        "    return img + imggrad*(strength * 0.01 / (np.abs(imggrad).mean()+1e-7))\n",
        "\n",
        "# Applies deepdream at multiple scales\n",
        "def render_deepdream(t_obj, input_img, show_steps = True):\n",
        "    # Collapse the optimization objective to a single number (the loss)\n",
        "    t_score = tf.reduce_mean(t_obj)\n",
        "    # We need the gradient of the image with respect to the objective\n",
        "    t_grad = tf.gradients(t_score, t_input)[0]\n",
        "\n",
        "    # split the image into a number of octaves (laplacian pyramid)\n",
        "    img = input_img\n",
        "    octaves = []\n",
        "    for i in range(octave_n-1):\n",
        "        lo = resize(img, np.int32(np.float32(img.shape[:2])/octave_scale))\n",
        "        octaves.append(img-resize(lo, img.shape[:2]))\n",
        "        img = lo\n",
        "\n",
        "    # generate details octave by octave\n",
        "    for octave in range(octave_n):\n",
        "        if octave>0:\n",
        "            hi = octaves[-octave]\n",
        "            img = resize(img, hi.shape[:2])+hi\n",
        "        for i in range(iter_n):\n",
        "            img = calc_grad_tiled(img, t_grad)\n",
        "        if show_steps:\n",
        "            clear_output()\n",
        "            showarray(img)\n",
        "    return img\n",
        "\n",
        "  \n",
        "# Settings for the image\n",
        "octave_n = 6\n",
        "octave_scale = 1.6\n",
        "iter_n = 20\n",
        "strength = 200\n",
        "layer = \"mixed4c\"\n",
        "\n",
        "final = render_deepdream(tf.square(T(layer)), img0)\n",
        "showarray(img0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BT9gdS7viJZa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assignment questions\n",
        "\n",
        "After you've worked on some code, answer the following questions in this text block:\n",
        "\n",
        "1.  Describe in a paragraph of text what you did and why, as if you were writing an email to somebody interested but nontechnical.\n",
        "\n",
        "The output image above uses Google DeepDream to take an input image, and edit it using machine learning (a CNN pre-configured model) to generate the image by increasing the probability of defining an area of the picture as a dog. It then looks at the gradient of the pixels to increase the probability of defining these areas as \"dogs\", increases or decreases the pixel values to increase probability, and repeating until the desired output is acheived. It is the equivalent of looking for animals or people in clouds.\n",
        "\n",
        "2.  What was the most challenging part of what you did?\n",
        "\n",
        "Getting the image in the correct format (i.e. importing it, removing alpha channel, removing unneccessary code...)\n",
        "\n",
        "3.  What was the most interesting thing you learned?\n",
        "\n",
        "Mainly the fact that this exists and has already gotten to this point.\n",
        "\n",
        "4.  What area would you like to explore with more time?\n",
        "\n",
        "How the model was trained and some of the math behind it.\n"
      ]
    },
    {
      "metadata": {
        "id": "_XXg2crAipwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stretch goals and resources\n",
        "\n",
        "Following are *optional* things for you to take a look at. Focus on the above assignment first, and make sure to commit and push your changes to GitHub (and since this is the first assignment of the sprint, open a PR as well).\n",
        "\n",
        "- [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
        "- [scikit-learn documentation](http://scikit-learn.org/stable/documentation.html)\n",
        "- [matplotlib documentation](https://matplotlib.org/contents.html)\n",
        "- [Awesome Data Science](https://github.com/bulutyazilim/awesome-datascience) - a list of many types of DS resources\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "- Find and read blogs, walkthroughs, and other examples of people working through cool things with data science - and share with your classmates!\n",
        "- Write a blog post (Medium is a popular place to publish) introducing yourself as somebody learning data science, and talking about what you've learned already and what you're excited to learn more about"
      ]
    }
  ]
}